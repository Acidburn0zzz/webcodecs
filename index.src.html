<pre class='metadata'>
Title: WebCodecs
Repository: wicg/web-codecs
Status: CG-DRAFT
ED: https://wicg.github.io/web-codecs/
Shortname: web-codecs
Level: 1
Group: wicg
Editor: Chris Cunningham, w3cid 114832, Google Inc. https://google.com/
Editor: Paul Adenot, w3cid 62410, Mozilla https://www.mozilla.org/

Abstract: This specification defines interfaces for encoding and decoding audio
Abstract: and video. It also includes an interface for retrieving raw video
Abstract: frames from MediaStreamStracks.

Markup Shorthands:css no, markdown yes, dfn yes
!Participate: <a href="https://github.com/wicg/web-codecs">Git Repository.</a>
!Participate: <a href="https://github.com/wicg/web-codecs/issues/new">File an issue.</a>
!Version History: <a href="https://github.com/wicg/web-codecs/commits">https://github.com/wicg/web-codecs/commits</a>
</pre>

<pre class='anchors'>
spec: media-source; urlPrefix: https://www.w3.org/TR/media-source/
    type: method
        for: MediaSource; text: isTypeSupported(); url: #dom-mediasource-istypesupported

spec: html; urlPrefix: https://html.spec.whatwg.org/multipage/;
    type: method
        for: HTMLMediaElement; text: canPlayType(); url: #dom-navigator-canplaytype
    type: attribute
        for: PlatformObject; text: [[Detached]]; url: structured-data.html#detached
    type: attribute
        for: ImageBitmap; text: resizeWidth; url:#dom-imagebitmapoptions-resizewidth
    type: attribute
        for: ImageBitmap; text: resizeHeight; url:#dom-imagebitmapoptions-resizeheight

spec: mediacapture-streams; urlPrefix: https://www.w3.org/TR/mediacapture-streams/
    type: method
        for: mediaDevices; text: getUserMedia(); url: #dom-mediadevices-getusermedia

spec: mediacapture-screen-share; urlPrefix: https://w3c.github.io/mediacapture-screen-share/
    type: method
        for: mediaDevices; text: getDisplayMedia(); url: #dom-mediadevices-getdisplaymedia

spec: mediacapture-main; urlPrefix: https://w3c.github.io/mediacapture-main/
    type: enum-value
        for:MediaStreamTrackState; text: live; url: #idl-def-MediaStreamTrackState.live
    type: enum-value
        for:MediaStreamTrackState; text: ended; url: #idl-def-MediaStreamTrackState.ended

spec: mimesniff; urlPrefix: https://mimesniff.spec.whatwg.org/#
    type: dfn; text: MIME type; url: mime-type

spec: infra; urlPrefix: https://infra.spec.whatwg.org/#
    type: dfn; text: queue; url: queues
    type: dfn; text: enqueing; url: queue-enqueue;
    type: dfn; text: dequeued; url: queue-dequeue;
    type: dfn; text: empty; url: list-is-empty;
</pre>


Definitions {#definitions}
==========================

: Codec
:: Refers generically to an instance of AudioDecoder, AudioEncoder,
    VideoDecoder, or VideoEncoder.

: Key Frame
:: An encoded frame that does not depend on any other frames for decoding.

: <dfn>Internal Pending Output</dfn>
:: Codec outputs such as {{VideoFrame}}s that currently reside in the internal
    pipeline of the underlying codec implementation. The underlying codec
    implementation may emit new outputs only when a new inputs are provided. The
    underlying codec implementation must emit all outputs in response to a
    flush.

: <dfn lt="AVC">Advanced Video Coding (AVC)</dfn>
:: Also known as H.264. Refers to the methods of video compression as defined by
    [[!iso14496-10]].

: <dfn lt="Picture Parameter Set (PPS)|PPS">Picture Parameter Set (PPS)</dfn>
:: A set of parameters describing <a>AVC</a> coded pictures as defined by
    [[!iso14496-10]].

: <dfn lt="Sequence Parameter Set (SPS)|SPS">Sequence Parameter Set (SPS)</dfn>
:: A set of parameters describing a sequence of <a>AVC</a> coded video as
    defined by [[!iso14496-10]].

Codec Processing Model {#codec-processing-model}
================================================

New codec tasks may be scheduled while previous tasks are still pending. For
example, web authors may call `decode()` without waiting for the previous
`decode()` to generate an output. This is facilitated by the following
mechanisms.

Each codec has a single <dfn>control message queue</dfn> that is a <a>queue</a>
of <dfn>control messages</dfn>.

<dfn lt="Enqueues a control message|Queue a control message">Queuing a control
    message</dfn> means <a>enqueing</a> the message to the codec’s <a>control
    message queue</a>. Invoking codec methods will often queue a control message
    to schedule work.

<dfn lt="running a control message|control message steps">Running a control
    message</dfn> means performing a sequence of steps specified by the method
    that enqueued the message.

The steps of a control message may depend on <dfn>injected state</dfn>, supplied
by the method that enqueud the message.

<dfn lt="Run the control message processing loop">Running the control message
    processing loop</dfn> means performing these steps.
1. While the control message queue is not <a>empty</a>
    1. Let |front message| be the next <a>dequeued</a> <a>control message</a>
    2. If |front message| cannot be performd now, return.

        The User Agent must decide when further processing is blocked because of
            ongoing work as an implementation detail (e.g. the underlying
            decoder cannot accept more requests yet). The UA must restart the
            processing loop when the blockage is resolved.

        NOTE: a blocked processing loop is visible to authors via the
            `decodeQueueSize` and `encodeQueueSize` attributes.

    3. Dequeue |front message| from the <a>control message queue</a>.
    4. Run the |front message| <a>control message steps</a>.

<dfn lt="Reset the control message queue">Resetting the control message
    queue</dfn> means performing these steps:
1. For each <a>control message</a> in the <a>control message queue</a>:
    1. If a control message's <a>injected state</a> includes a promise, reject
        that promise.
    2. Remove the message from the queue.

AudioDecoder Interface {#audiodecoder-interface}
================================================

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface AudioDecoder {
  constructor(AudioDecoderInit init);

  readonly attribute CodecState state;
  readonly attribute long decodeQueueSize;

  undefined configure(AudioDecoderConfig config);
  undefined decode(EncodedAudioChunk chunk);
  Promise<undefined> flush();
  undefined reset();
  undefined close();
};

dictionary AudioDecoderInit {
  required AudioFrameOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback AudioFrameOutputCallback = undefined(AudioFrame output);
</xmp>
</pre>

Internal Slots {#audiodecoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=AudioDecoder>[[codec implementation]]</dfn></dt>
<dd>Underlying decoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=AudioDecoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for decoded outputs.</dd>
<dt><dfn attribute for=AudioDecoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for decode errors.</dd>
</dl>

Constructors {#audiodecoder-constructors}
-----------------------------------------
<dfn constructor for=AudioDecoder title="AudioDecoder(init)">
  AudioDecoder(init)
</dfn>
1. Let d be a new {{AudioDecoder}} object.
2. Assign init.output to the {{AudioDecoder/[[output callback]]}} internal slot.
3. Assign init.error to the {{AudioDecoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to d.state.
4. Return d.

Attributes {#audiodecoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=AudioDecoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=AudioDecoder>decodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending decode requests. This does not include requests that
    have been sent to the underlying codec.
  </dd>
</dl>

Methods {#audiodecoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=AudioDecoder>configure(config)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to configure the audio decoder for
    decoding chunks as described by |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid AudioDecoderConfig</a>, throw a
        {{TypeError}}.
    2. If {{AudioDecoder/state}} is `“closed”`, throw an {{InvalidStateError}}.
    3. If the user agent cannot provide a codec implementation to support
        |config|, throw a {{NotSupportedError}}.
    4. Set {{AudioDecoder/state}} to `"configured"`.
    5. <a>Queue a control message</a> to configure the decoder with |config|.
    6. <a>Run the control message processing loop</a>.

    <a>Running a control message</a> to configure the decoder means running
    these steps:
    1. Assign {{AudioDecoder/[[codec implementation]]}} with an implementation
        supporting |config|.
  </dd>

  <dt><dfn method for=AudioDecoder>decode(chunk)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to decode the given |chunk|.

    When invoked, run these steps:
    1. If {{AudioDecoder/state}} is not `"configured"`, throw an
        {{InvalidStateError}}.
    2. Increment {{AudioDecoder/decodeQueueSize}}.
    3. <a>Queue a control message</a> to decode the |chunk|.
    4. <a>Run the control message processing loop</a>.

    Running a control message to decode the chunk means performing these steps:
    1. Decrement {{AudioDecoder/decodeQueueSize}}
    2. Let |codec implementation queue| be the result of starting a new
        <a>parallel queue</a>.
    3. Enqueue the following steps to |codec implementation queue|:
        1. Attempt to use {{AudioDecoder/[[codec implementation]]}} to decode
            the chunk.
        2. If decoding results in an error, queue a task on the media element
            task source to run the <a>Close AudioDecoder</a> algorithm with
            {{EncodingError}}.
        3. Otherwise, for each decoded audio data |output|, queue a task on the
            media element task source to run the <a>Output AudioFrame</a>
            algorithm with |output|.
  </dd>

  <dt><dfn method for=AudioDecoder>flush()</dfn></dt>
  <dd>
    Completes all <a>control messages</a> in the <a>control message queue</a>
    and emits all outputs.

    When invoked, run these steps:
    1. If {{AudioDecoder/state}} is not `"configured"`, return
        [=a promise rejected with=] {{InvalidStateError}} {{DOMException}}.
    2. Let |promise| be a new Promise.
    3. <a>Queue a control message</a> to flush the codec with |promise|.
    4. Return |promise|.

    Running a control message to flush the codec means performing these steps
        with |promise|.
    1. Signal {{AudioDecoder/[[codec implementation]]}} to emit all <a>internal
        pending outputs</a>.
    2. For each decoded audio data |output|, queue a task on the media element
        task source to run the <a>Output AudioFrame</a> algorithm with |output|.
    3. Queue a task on the media element task source to resolve |promise|.
  </dd>

  <dt><dfn method for=AudioDecoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    <a>control messages</a> in the <a>control message queue</a>, and all pending
    callbacks.

    When invoked, run the <a>Reset AudioDecoder</a> algorithm.
  </dd>

  <dt><dfn method for=AudioDecoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases system resources. Close is
    permanent.

    When invoked, run the <a>Close AudioDecoder</a> algorithm.
  </dd>
</dl>

Algorithms {#audiodecoder-algorithms}
-------------------------------------
<dl>
  <dt><dfn>Output AudioFrame</dfn> (with |output|)</dt>
  <dd>
    Run these steps:
    1. Let |buffer| be an {{AudioBuffer}} containing the decoded audio data in
        |output|.
    2. Let |frame| be an {{AudioFrame}} containing |buffer| and a timestamp for
        the output.
    3. Invoke {{AudioDecoder/[[output callback]]}} with frame.
  </dd>
  <dt><dfn>Reset AudioDecoder</dfn></dt>
  <dd>
    Run these steps:
    1. If {{AudioDecoder/state}} is `“closed”`, throw an {{InvalidStateError}}.
    2. Set {{AudioDecoder/state}} to `“unconfigured”`.
    3. Signal {{AudioDecoder/[[codec implementation]]}} to cease producing
        output for the previous configuration.
    4. <a>Reset the control message queue</a>.
  </dd>
  <dt><dfn>Close AudioDecoder</dfn> (with error)</dt>
  <dd>
    Run these steps:
    1. Run the <a>Reset AudioDecoder</a> algorithm.
    2. Set {{AudioDecoder/state}} to `“closed”`.
    3. Clear {{AudioDecoder/[[codec implementation]]}} and release associated
        system resources.
    4. If |error| is set, queue a task on the media element task source to
        invoke the {{AudioDecoder/[[error callback]]}} with |error|.
  </dd>
</dl>

VideoDecoder Interface {#videodecoder-interface}
================================================

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface VideoDecoder {
  constructor(VideoDecoderInit init);

  readonly attribute CodecState state;
  readonly attribute long decodeQueueSize;

  undefined configure(VideoDecoderConfig config);
  undefined decode(EncodedVideoChunk chunk);
  Promise<undefined> flush();
  undefined reset();
  undefined close();
};

dictionary VideoDecoderInit {
  required VideoFrameOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback VideoFrameOutputCallback = undefined(VideoFrame output);
</xmp>
</pre>

Internal Slots {#videodecoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=VideoDecoder>[[codec implementation]]</dfn></dt>
<dd>Underlying decoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=VideoDecoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for decoded outputs.</dd>
<dt><dfn attribute for=VideoDecoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for decode errors.</dd>
</dl>

Constructors {#videodecoder-constructors}
-----------------------------------------
<dfn constructor for=VideoDecoder title="VideoDecoder(init)">
  VideoDecoder(init)
</dfn>
1. Let d be a new VideoDecoder object.
2. Assign `init.output` to the {{VideoDecoder/[[output callback]]}} internal slot.
3. Assign `init.error` to the {{VideoDecoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to `d.state`.
5. Return d.

Attributes {#videodecoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=VideoDecoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=VideoDecoder>decodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending decode requests. This does not include requests that
    have been sent to the underlying codec.
  </dd>
</dl>

Methods {#videodecoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=VideoDecoder>configure(config)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to configure the video decoder for
    decoding chunks as described by |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid VideoDecoderConfig</a>, throw a
        {{TypeError}}.
    2. If {{VideoDecoder/state}} is `“closed”`, throw an {{InvalidStateError}}.
    3. If the user agent cannot provide a codec implementation to support
        |config|, throw a {{NotSupportedError}}.
    4. Set {{VideoDecoder/state}} to `"configured"`.
    5. <a>Queue a control message</a> to configure the decoder with |config|.
    6. <a>Run the control message processing loop</a>.

    <a>Running a control message</a> to configure the decoder means running
    these steps:
    1. Assign {{VideoDecoder/[[codec implementation]]}} with an implementation
        supporting |config|.
  </dd>

  <dt><dfn method for=VideoDecoder>decode(chunk)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to decode the given |chunk|.

    When invoked, run these steps:
    1. If {{VideoDecoder/state}} is not `"configured"`, throw an
        {{InvalidStateError}}.
    2. Increment {{VideoDecoder/decodeQueueSize}}.
    3. <a>Queue a control message</a> to decode the |chunk|.
    4. <a>Run the control message processing loop</a>.

    Running a control message to decode the chunk means performing these steps:
    1. Decrement {{VideoDecoder/decodeQueueSize}}
    2. Let |codec implementation queue| be the result of starting a new
        <a>parallel queue</a>.
    3. Enqueue the following steps to |codec implementation queue|:
        1. Attempt to use {{VideoDecoder/[[codec implementation]]}} to decode
            the chunk.
        2. If decoding results in an error, queue a task on the media element
            task source to run the <a>Close VideoDecoder</a> algorithm with
            {{EncodingError}}.
        3. Otherwise, for each decoded video frame data |output|, queue a task
            on the media element task source to run the <a>Output VideoFrame</a>
            algorithm with |output|.
  </dd>

  <dt><dfn method for=VideoDecoder>flush()</dfn></dt>
  <dd>
    Completes all <a>control messages</a> in the <a>control message queue</a>
    and emits all outputs.

    When invoked, run these steps:
    1. If {{VideoDecoder/state}} is not `"configured"`, return
        [=a promise rejected with=] {{InvalidStateError}} {{DOMException}}.
    2. Let |promise| be a new Promise.
    3. <a>Queue a control message</a> to flush the codec with |promise|.
    4. Return |promise|.

    Running a control message to flush the codec means performing these steps
        with |promise|.
    1. Signal {{VideoDecoder/[[codec implementation]]}} to emit all <a>internal
        pending outputs</a>.
    2. For each decoded video frame data |output|, queue a task on the media
        element task source to run the <a>Output VideoFrame</a> algorithm with
        |output|.
    3. Queue a task on the media element task source to resolve |promise|.
  </dd>

  <dt><dfn method for=VideoDecoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    <a>control messages</a> in the <a>control message queue</a>, and all pending
    callbacks.

    When invoked, run the <a>Reset VideoDecoder</a> algorithm.
  </dd>

  <dt><dfn method for=VideoDecoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases system resources. Close is
    permanent.

    When invoked, run the <a>Close VideoDecoder</a> algorithm.
  </dd>
</dl>

Algorithms {#videodecoder-algorithms}
-------------------------------------
<dl>
  <dt><dfn>Output VideoFrame</dfn> (with |output|)</dt>
  <dd>
    Run these steps:
    1. Let |planes| be a sequence of {{Plane}}s containing the decoded video
        frame data from |output|.
    2. Let |pixelFormat| be the {{PixelFormat}} of |planes|.
    3. Let |frameInit| be a {{VideoFrameInit}} with the following keys:
        1. Let {{VideoFrameInit/timestamp}} and {{VideoFrameInit/duration}} be
            the {{EncodedVideoChunk/timestamp}} and
            {{EncodedVideoChunk/duration}} from the {{EncodedVideoChunk}}
            associated with |output|.
        2. Let {{VideoFrameInit/codedWidth}} and {{VideoFrameInit/codedHeight}}
            be the width and height of the decoded video frame |output| in
            pixels, prior to any cropping or aspect ratio adjustments.
        3. Let {{VideoFrameInit/cropLeft}}, {{VideoFrameInit/cropTop}},
            {{VideoFrameInit/cropWidth}}, and {{VideoFrameInit/cropHeight}} be
            the crop region of the decoded video frame |output| in pixels,
            prior to any aspect ratio adjustments.
        4. Let {{VideoFrameInit/displayWidth}} and
            {{VideoFrameInit/displayHeight}} be the display size of the decoded
            video frame in pixels.
    4. Let |frame| be a {{VideoFrame}}, constructed with |pixelFormat|,
        |planes|, and |frameInit|.
    5. Invoke {{VideoDecoder/[[output callback]]}} with |frame|.
  </dd>
  <dt><dfn>Reset VideoDecoder</dfn></dt>
  <dd>
    Run these steps:
    1. If {{VideoDecoder/state}} is `“closed”`, throw an {{InvalidStateError}}.
    2. Set {{VideoDecoder/state}} to `“unconfigured”`.
    3. Signal {{VideoDecoder/[[codec implementation]]}} to cease producing
        output for the previous configuration.
    4. <a>Reset the control message queue</a>.
  </dd>
  <dt><dfn>Close VideoDecoder</dfn> (with error)</dt>
  <dd>
    Run these steps:
    1. Run the <a>Reset VideoDecoder</a> algorithm.
    2. Set {{VideoDecoder/state}} to `“closed”`.
    3. Clear {{VideoDecoder/[[codec implementation]]}} and release associated
        system resources.
    4. If |error| is set, queue a task on the media element task source to
        invoke the {{VideoDecoder/[[error callback]]}} with |error|.
  </dd>
</dl>


AudioEncoder Interface {#audioencoder-interface}
================================================

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface AudioEncoder {
  constructor(AudioEncoderInit init);

  readonly attribute CodecState state;
  readonly attribute long encodeQueueSize;

  undefined configure(AudioEncoderConfig config);
  undefined encode(AudioFrame frame);
  Promise<undefined> flush();
  undefined reset();
  undefined close();
};

dictionary AudioEncoderInit {
  required EncodedAudioChunkOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback EncodedAudioChunkOutputCallback = undefined(EncodedAudioChunk output);
</xmp>
</pre>

Internal Slots {#audioencoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=AudioEncoder>[[codec implementation]]</dfn></dt>
<dd>Underlying encoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=AudioEncoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for encoded outputs.</dd>
<dt><dfn attribute for=AudioEncoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for encode errors.</dd>
</dl>

Constructors {#audioencoder-constructors}
-----------------------------------------
<dfn constructor for=AudioEncoder title="AudioEncoder(init)">
  AudioEncoder(init)
</dfn>
1. Let e be a new AudioEncoder object.
2. Assign `init.output` to the {{AudioEncoder/[[output callback]]}} internal slot.
3. Assign `init.error` to the {{AudioEncoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to `e.state`.
5. Return e.

Attributes {#audioencoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=AudioEncoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=AudioEncoder>encodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending encode requests. This does not include requests that
    have been sent to the underlying codec.
  </dd>
</dl>

Methods {#audioencoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=AudioEncoder>configure(config)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to configure the audio encoder for
    decoding chunks as described by |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid AudioEncoderConfig</a>, throw a
        {{TypeError}}.
    2. If {{AudioEncoder/state}} is `"closed"`, throw an {{InvalidStateError}}.
    3. If the user agent cannot provide a codec implementation to support
        |config|, throw a {{NotSupportedError}}.
    4. Set {{AudioEncoder/state}} to `"configured"`.
    5. <a>Queue a control message</a> to configure the encoder using |config|.
    6. <a>Run the control message processing loop</a>.

    Running a control message to configure the encoder means performing these
    steps:
    1. Assign {{AudioEncoder/[[codec implementation]]}} with an implementation
        supporting |config|.
  </dd>

  <dt><dfn method for=AudioEncoder>encode(frame)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to encode the given |frame|.

    NOTE: This method will destroy the AudioFrame. Authors who wish to retain a
    copy, should call `frame.clone()` prior to calling encode().

    When invoked, run these steps:
    1. If the value of |frame|'s {{AudioFrame/[[detached]]}} internal slot is
        `true`, throw a {{TypeError}}.
    2. If {{AudioEncoder/state}} is not `"configured"`, throw an
        {{InvalidStateError}}.
    3. Let |frameClone| hold the result of running the <a>Clone Frame</a>
        algorithm with |frame|.
    4. Destroy the original |frame| by invoking `frame.destroy()`.
    5. Increment {{AudioEncoder/encodeQueueSize}}.
    6. <a>Queue a control message</a> to encode |frameClone|.
    7. Run the control message processing loop.

    Running a control message to encode the frame means performing these steps.
    1. Decrement {{AudioEncoder/encodeQueueSize}}.
    2. Let |codec implementation queue| be the result of starting a new
        <a>parallel queue</a>.
    3. Enqueue the following steps to |codec implementation queue|:
        1. Attempt to use {{AudioEncoder/[[codec implementation]]}} to encode
            |frameClone|.
        2. If encoding results in an error, queue a task on the media element
            task source to run the <a>Close AudioEncoder</a> algorithm with
            {{EncodingError}}.
        3. Otherwise, for each encoded audio data |output|, queue a task on the
            media element task source to run the <a>Output EncodedAudioChunk</a>
            algorithm with |output|.
  </dd>

  <dt><dfn method for=AudioEncoder>flush()</dfn></dt>
  <dd>
    Completes all <a>control messages</a> in the <a>control message queue</a>
    and emits all outputs.

    When invoked, run these steps:
    1. If {{AudioEncoder/state}} is not `"configured"`, return
        [=a promise rejected with=] {{InvalidStateError}} {{DOMException}}.
    2. Let |promise| be a new Promise.
    3. <a>Queue a control message</a> to flush the codec with |promise|.
    4. Return |promise|.

    Running a control message to flush the codec means performing these steps
        with |promise|.
    1. Signal {{AudioEncoder/[[codec implementation]]}} to emit all <a>internal
        pending outputs</a>.
    2. For each encoded audio data |output|, queue a task on the media element
        task source to run the <a>Output EncodedAudioChunk</a> algorithm with
        |output|.
    3. Queue a task on the media element task source to resolve |promise|.
  </dd>

  <dt><dfn method for=AudioEncoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    <a>control messages</a> in the <a>control message queue</a>, and all pending
    callbacks.

    When invoked, run the <a>Reset AudioEncoder</a> algorithm.
  </dd>

  <dt><dfn method for=AudioEncoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases system resources. Close is
    permanent.

    When invoked, run the <a>Close AudioEncoder</a> algorithm.
  </dd>
</dl>

Algorithms {#audioencoder-algorithms}
-------------------------------------
<dl>
  <dt><dfn>Output EncodedAudioChunk</dfn> (with |output|)</dt>
  <dd>
    Run these steps:
    1. Let |chunkInit| be an {{EncodedAudioChunkInit}} with the following keys:
        1. Let {{EncodedAudioChunkInit/data}} contain the encoded audio data
            from |output|.
        2. Let {{EncodedAudioChunkInit/type}} be the {{EncodedAudioChunkType}}
            of |output|.
        3. Let {{EncodedAudioChunkInit/timestamp}} be the
            {{AudioFrame/timestamp}} from the AudioFrame associated with
            |output|.
    2. Let |chunk| be a new {{EncodedAudioChunk}} constructed with |chunkInit|.
    3. Invoke {{AudioEncoder/[[output callback]]}} with |chunk|.
  </dd>
  <dt><dfn>Reset AudioEncoder</dfn></dt>
  <dd>
    Run these steps:
    1. If {{AudioEncoder/state}} is `“closed”`, throw an {{InvalidStateError}}.
    2. Set {{AudioEncoder/state}} to `“unconfigured”`.
    3. Signal {{AudioEncoder/[[codec implementation]]}} to cease producing
        output for the previous configuration.
    4. <a>Reset the control message queue</a>.
  </dd>
  <dt><dfn>Close AudioEncoder</dfn></dt>
  <dd>
    Run these steps:
    1. Run the <a>Reset AudioEncoder</a> algorithm.
    2. Set {{AudioEncoder/state}} to `“closed”`.
    3. Clear {{AudioEncoder/[[codec implementation]]}} and release associated
        system resources.
    4. If |error| is set, queue a task on the media element task source to
        invoke the {{AudioEncoder/[[error callback]]}} with |error|.
  </dd>
</dl>

VideoEncoder Interface {#videoencoder-interface}
================================================

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface VideoEncoder {
  constructor(VideoEncoderInit init);

  readonly attribute CodecState state;
  readonly attribute long encodeQueueSize;

  undefined configure(VideoEncoderConfig config);
  undefined encode(VideoFrame frame, optional VideoEncoderEncodeOptions options = {});
  Promise<undefined> flush();
  undefined reset();
  undefined close();
};

dictionary VideoEncoderInit {
  required EncodedVideoChunkOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback EncodedVideoChunkOutputCallback = undefined(EncodedVideoChunk output, VideoDecoderConfig? output_config);
</xmp>
</pre>

Internal Slots {#videoencoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=VideoEncoder>[[codec implementation]]</dfn></dt>
<dd>Underlying encoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=VideoEncoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for encoded outputs.</dd>
<dt><dfn attribute for=VideoEncoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for encode errors.</dd>
<dt><dfn attribute for=VideoEncoder>[[active encoder config]]</dfn></dt>
<dd>The {{VideoEncoderConfig}} that is actively applied.</dd>
<dt><dfn attribute for=VideoEncoder>[[active output config]]</dfn></dt>
<dd>
  The {{VideoDecoderConfig}} that describes how to decode the most recently
  emitted {{EncodedVideoChunk}}.
</dd>
</dl>

Constructors {#videoencoder-constructors}
-----------------------------------------
<dfn constructor for=VideoEncoder title="VideoEncoder(init)">
  VideoEncoder(init)
</dfn>
1. Let e be a new VideoEncoder object.
2. Assign `init.output` to the {{VideoEncoder/[[output callback]]}} internal slot.
3. Assign `init.error` to the {{VideoEncoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to `e.state`.
5. Return e.

Attributes {#videoencoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=VideoEncoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=VideoEncoder>encodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending encode requests. This does not include requests that
    have been sent to the underlying codec.
  </dd>
</dl>

Methods {#videoencoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=VideoEncoder>configure(config)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to configure the video encoder for
    decoding chunks as described by |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid VideoEncoderConfig</a>, throw a
        {{TypeError}}.
    2. If {{VideoEncoder/state}} is `"closed"`, throw an {{InvalidStateError}}.
    3. If the user agent cannot provide a codec implementation to support
        |config|, throw a {{NotSupportedError}}.
    4. Set {{VideoEncoder/state}} to `"configured"`.
    5. <a>Queue a control message</a> to configure the encoder using |config|.
    6. <a>Run the control message processing loop</a>.

    Running a control message to configure the encoder means performing these
    steps:
    1. Assign {{VideoEncoder/[[codec implementation]]}} with an implementation
        supporting |config|.
    2. Set {{VideoEncoder/[[active encoder config]]}} to `config`.
  </dd>

  <dt><dfn method for=VideoEncoder>encode(frame, options)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to encode the given |frame|.

    NOTE: This method will destroy the VideoFrame. Authors who wish to retain a
    copy, should call `frame.clone()` prior to calling encode().

    When invoked, run these steps:
    1. If the value of |frame|'s {{VideoFrame/[[detached]]}} internal slot is
        `true`, throw a {{TypeError}}.
    2. If {{VideoEncoder/state}} is not `"configured"`, throw an
        {{InvalidStateError}}.
    3. Let |frameClone| hold the result of running the <a>Clone Frame</a>
        algorithm with |frame|.
    4. Destroy the original |frame| by invoking `frame.destroy()`.
    5. Increment {{VideoEncoder/encodeQueueSize}}.
    6. <a>Queue a control message</a> to encode |frameClone|.
    7. Run the control message processing loop.

    Running a control message to encode the frame means performing these steps.
    1. Decrement {{VideoEncoder/encodeQueueSize}}.
    2. Let |codec implementation queue| be the result of starting a new
        <a>parallel queue</a>.
    3. Enqueue the following steps to |codec implementation queue|:
        1. Attempt to use {{VideoEncoder/[[codec implementation]]}} to encode
            |frameClone| according to |options|.
        2. If encoding results in an error, queue a task on the media element
            task source to run the <a>Close VideoEncoder</a> algorithm with
            {{EncodingError}}.
        3. Otherwise, for each encoded video data |output|, queue a task on the
            media element task source to run the <a>Output EncodedVideoChunk</a> algorithm with |output| and
            {{VideoEncoder/[[active encoder config]]}}.
  </dd>

  <dt><dfn method for=VideoEncoder>flush()</dfn></dt>
  <dd>
    Completes all <a>control messages</a> in the <a>control message queue</a>
    and emits all outputs.

    When invoked, run these steps:
    1. If {{VideoEncoder/state}} is not `"configured"`, return
        [=a promise rejected with=] {{InvalidStateError}} {{DOMException}}.
    2. Let |promise| be a new Promise.
    3. <a>Queue a control message</a> to flush the codec with |promise|.
    4. Return |promise|.

    Running a control message to flush the codec means performing these steps
        with |promise|.
    1. Signal {{VideoEncoder/[[codec implementation]]}} to emit all<a>internal
        pending outputs</a>.
    2. For each encoded video data |output|, queue a task on the media element
        task source to run the <a>Output EncodedVideoChunk</a> algorithm with
        |output| and {{VideoEncoder/[[active encoder config]]}}.
    3. Queue a task on the media element task source to resolve |promise|.
  </dd>

  <dt><dfn method for=VideoEncoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    <a>control messages</a> in the <a>control message queue</a>, and all pending
    callbacks.

    When invoked, run the <a>Reset VideoEncoder</a> algorithm.
  </dd>

  <dt><dfn method for=VideoEncoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases system resources. Close is
    permanent.

    When invoked, run the <a>Close VideoEncoder</a> algorithm.
  </dd>
</dl>

Algorithms {#videoencoder-algorithms}
-------------------------------------
<dl>
  <dt>
    <dfn>Output EncodedVideoChunk</dfn> (with |output| and
    <var ignore=''>encoder_config</var>)
  </dt>
  <dd>
    Run these steps:
    1. Let |output_config| be a {{VideoDecoderConfig}} that describes |output|.
        Initialize |output_config| as follows:
        1. Assign `encoder_config.codec` to `output_config.codec`.
        2. Assign `encoder_config.cropWidth` to `output_config.cropWidth`.
        3. Assign `encoder_config.cropHeight` to `output_config.cropHeight`.
        4. Assign `encoder_config.displayWidth` to `output_config.displayWidth`.
        5. Assign `encoder_config.displayHeight` to
            `output_config.displayHeight`.
        6. Assign the remaining keys of `output_config` as determined by
            {{VideoEncoder/[[codec implementation]]}}. The user agent
            must ensure that the configuration is completely described
            such that |output_config| could be used to correctly decode
            |output|.

            NOTE: This includes supplying the
                {{VideoDecoderConfig/description}} to describe codec
                specific "extradata" like the avcC bytes for AVC.
    2. If |output_config| and {{VideoEncoder/[[active output config]]}} are
        <a>equal dictionaries</a>, set |output_config| to null. Otherwise, set
        {{VideoEncoder/[[active output config]]}} to |output_config|.

        NOTE: The {{VideoDecoderConfig}} |output_config| will be `null`
            if the configuration hasn't changed from previous outputs. The first
            output will always include a non-null |output_config|.

   3. Let |chunkInit| be an {{EncodedVideoChunkInit}} with the following keys:
        1. Let {{EncodedVideoChunkInit/data}} contain the encoded video data
            from |output|.
        2. Let {{EncodedVideoChunkInit/type}} be the {{EncodedVideoChunkType}}
            of |output|.
        3. Let {{EncodedVideoChunkInit/timestamp}} be the
            {{VideoFrame/timestamp}} from the {{VideoFrame}} associated with
            |output|.
        4. Let {{EncodedVideoChunkInit/duration}} be the {{VideoFrame/duration}}
            from the {{VideoFrame}} associated with |output|.
    4. Let |chunk| be a new {{EncodedVideoChunk}} constructed with |chunkInit|.
    5. Invoke {{VideoEncoder/[[output callback]]}} with |chunk| and
        |output_config|.

  </dd>
  <dt><dfn>Reset VideoEncoder</dfn></dt>
  <dd>
    Run these steps:
    1. If {{VideoEncoder/state}} is `“closed”`, throw an {{InvalidStateError}}.
    2. Set {{VideoEncoder/state}} to `“unconfigured”`.
    3. Set {{VideoEncoder/[[active encoder config]]}} to `null`.
    4. Set {{VideoEncoder/[[active output config]]}} to `null`.
    5. Signal {{VideoEncoder/[[codec implementation]]}} to cease producing
        output for the previous configuration.
    6. <a>Reset the control message queue</a>.
  </dd>
  <dt><dfn>Close VideoEncoder</dfn></dt>
  <dd>
    Run these steps:
    1. Run the <a>Reset VideoEncoder</a> algorithm.
    2. Set {{VideoEncoder/state}} to `“closed”`.
    3. Clear {{VideoEncoder/[[codec implementation]]}} and release associated
        system resources.
    4. If |error| is set, queue a task on the media element task source to
        invoke the {{VideoEncoder/[[error callback]]}} with |error|.
  </dd>
</dl>


Configurations{#configurations}
===============================

<dfn export>Codec String</dfn>{#config-codec-string}
----------------------------------------------------
In other media specifications, codec strings historically accompanied a
    <a>MIME type</a> as the “codecs=” parameter
    ({{MediaSource/isTypeSupported()}}, {{HTMLMediaElement/canPlayType()}})
    [[RFC6381]]. In this specification, encoded media is not containerized; hence,
    only the value of the codecs parameter is accepted.

A <dfn>valid codec string</dfn> must meet the following conditions.
1. Is valid per the relevant codec specification (see examples below).

2. It describes a single codec.

NOTE: Not a comma separated list.

3. It is unambiguous about codec profile and level for codecs that define these
    concepts.


<div class='note'>
  NOTE: There is no unified specification for codec strings. Each codec has its
  own unique string format, specified by the authors of the codec. Relevant
  specifications include:

  * h264, aac - [[RFC6381]]
  * vp9 -
      <a href="https://www.webmproject.org/vp9/mp4/#codecs-parameter-string">
        https://www.webmproject.org/vp9/mp4/#codecs-parameter-string
      </a>
  * hevc -
      <a href="https://www.iso.org/standard/74429.html">
        ISO IEC 14496-15 dated 2012 or newer in the Annex E.3
      </a>
  * av1 -
      <a href="https://aomediacodec.github.io/av1-isobmff/#codecsparam">
        https://aomediacodec.github.io/av1-isobmff/#codecsparam
      </a>

</div>

<div class='example'>
Valid examples include:<br>
  * 'vp8'
  * 'vp09.00.10.08'
  * 'avc1.4D401E',
  * 'opus',
  * 'mp4a.40.2',
  * 'flac'

Invalid examples include:<br>
  * 'video/webm; codecs="vp8"' (invalid to supply full mimetype; valid as just
        'vp8')<br>
  * 'codecs="opus"' (invalid to include codecs= prefix)<br>
  * ‘flac,vorbis’ (describes more than one codec)<br>
  * ‘vp9’ (ambiguous about profile and level)<br>
  * 'video/mp4' (describes a container, not a codec)<br>

</div>


AudioDecoderConfig{#audio-decoder-config}
-----------------------------------------
<pre class='idl'>
<xmp>
dictionary AudioDecoderConfig {
  required DOMString codec;
  required unsigned long sampleRate;
  required unsigned long numberOfChannels;
  BufferSource description;
};
</xmp>
</pre>

To check if an {{AudioDecoderConfig}} is a <dfn>valid AudioDecoderConfig</dfn>,
    run these steps:
1. If codec is not a <a>valid codec string</a>, return `false`.
2. Return `true`.

<dl>
  <dt><dfn dict-member for=AudioDecoderConfig>codec</dfn></dt>
  <dd>Contains a <a>codec string</a> describing the codec.</dd>

  <dt><dfn dict-member for=AudioDecoderConfig>sampleRate</dfn></dt>
  <dd>The number of frame samples per second.</dd>

  <dt><dfn dict-member for=AudioDecoderConfig>numberOfChannels</dfn></dt>
  <dd>The number of audio channels.</dd>

  <dt><dfn dict-member for=AudioDecoderConfig>description</dfn></dt>
  <dd>
    A sequence of codec specific bytes, commonly known as extradata.

    NOTE: For example, the vorbis “code book”.
  </dd>
</dl>


VideoDecoderConfig{#video-decoder-config}
-----------------------------------------
<pre class='idl'>
<xmp>
dictionary VideoDecoderConfig {
  required DOMString codec;
  BufferSource description;
  required unsigned long codedWidth;
  required unsigned long codedHeight;
  unsigned long cropLeft;
  unsigned long cropTop;
  unsigned long cropWidth;
  unsigned long cropHeight;
  unsigned long displayWidth;
  unsigned long displayHeight;
  HardwareAcceleration acceleration = "allow";
};
</xmp>
</pre>

To check if a {{VideoDecoderConfig}} is a <dfn>valid VideoDecoderConfig</dfn>,
run these steps:
1. If {{VideoDecoderConfig/codec}} is not a <a>valid codec string</a>, return
    `false`.
2. If {{VideoDecoderConfig/codedWidth}} = 0 or
    {{VideoDecoderConfig/codedHeight}} = 0, return `false`.
3. If {{VideoDecoderConfig/cropWidth}} = 0 or {{VideoDecoderConfig/cropHeight}}
    = 0, return `false`.
4. If {{VideoDecoderConfig/cropTop}} + {{VideoDecoderConfig/cropHeight}} >=
    {{VideoDecoderConfig/codedHeight}}, return `false`.
5. If {{VideoDecoderConfig/cropLeft}} + {{VideoDecoderConfig/cropWidth}} >=
    {{VideoDecoderConfig/codedWidth}}, return `false`.
6. If {{VideoDecoderConfig/displayWidth}} = 0 or
    {{VideoDecoderConfig/displayHeight}} = 0, return `false`.
7. Return `true`.

<dl>
  <dt><dfn dict-member for=VideoDecoderConfig>codec</dfn></dt>
  <dd>Contains a codec string describing the codec.</dd>

  <dt><dfn dict-member for=VideoDecoderConfig>description</dfn></dt>
  <dd>
    A sequence of codec specific bytes, commonly known as extradata.

    NOTE: Examples include the VP9 vpcC bytes or the AVC avcC bytes.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>codedWidth</dfn></dt>
  <dd>
    Width of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>codedHeight</dfn></dt>
  <dd>
    Height of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>cropLeft</dfn></dt>
  <dd>
    The number of pixels to remove from the left of the VideoFrame, prior to
        aspect ratio adjustments. Defaults to zero if not present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>cropTop</dfn></dt>
  <dd>
    The number of pixels to remove from the top of the VideoFrame, prior to
        aspect ratio adjustments. Defaults to zero if not present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>cropWidth</dfn></dt>
  <dd>
    The width in pixels to include in the crop, starting from cropLeft.
        Defaults to codedWidth if not present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>cropHeight</dfn></dt>
  <dd>
    The height in pixels to include in the crop, starting from cropLeft.
        Defaults to codedHeight if not present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>displayWidth</dfn></dt>
  <dd>
    Width of the VideoFrame when displayed. Defaults to cropWidth if not
        present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>displayHeight</dfn></dt>
  <dd>
    Height of the VideoFrame when displayed. Defaults to cropHeight if not
        present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>acceleration</dfn></dt>
  <dd>
    Configures hardware accleration for this codec. See
    {{HardwareAcceleration}}.
  </dd>
</dl>


AudioEncoderConfig{#audio-encoder-config}
-----------------------------------------
<pre class='idl'>
<xmp>
dictionary AudioEncoderConfig {
  required DOMString codec;
  unsigned long sampleRate;
  unsigned long numberOfChannels;
};
</xmp>
</pre>

To check if an {{AudioEncoderConfig}} is a <dfn>valid AudioEncoderConfig</dfn>,
run these steps:
1. If {{AudioEncoderConfig/codec}} is not a <a>valid codec string</a>, return
    `false`.
2. Return `true`.

<dl>
  <dt><dfn dict-member for=AudioEncoderConfig>codec</dfn></dt>
  <dd>Contains a codec string describing the codec.</dd>

  <dt><dfn dict-member for=AudioEncoderConfig>sampleRate</dfn></dt>
  <dd>The number of frame samples per second.</dd>

  <dt><dfn dict-member for=AudioEncoderConfig>numberOfChannels</dfn></dt>
  <dd>The number of audio channels.</dd>
</dl>


VideoEncoderConfig{#video-encoder-config}
-----------------------------------------
<pre class='idl'>
<xmp>
dictionary VideoEncoderConfig {
  required DOMString codec;
  unsigned long long bitrate;
  required unsigned long cropWidth;
  required unsigned long cropHeight;
  unsigned long displayWidth;
  unsigned long displayHeight;
  HardwareAcceleration acceleration = "allow";

  AvcEncoderConfig avc;
};
</xmp>
</pre>

To check if a {{VideoEncoderConfig}} is a <dfn>valid VideoEncoderConfig</dfn>,
    run these steps:
1. If {{VideoEncoderConfig/codec}} is not a <a>valid codec string</a>, return
    `false`.
2. If {{VideoEncoderConfig/cropWidth}} = 0 or {{VideoEncoderConfig/cropHeight}}
    = 0, return `false`.
3. If {{VideoEncoderConfig/displayWidth}} = 0 or
    {{VideoEncoderConfig/displayHeight}} = 0, return `false`.
4. If {{VideoEncoderConfig/avc}} is present, but {{VideoEncoderConfig/codec}}
    does not describe the <a>AVC</a> codec, per [[RFC6381]], return `false`.
4. Return `true`.

<dl>
  <dt><dfn dict-member for=VideoEncoderConfig>codec</dfn></dt>
  <dd>Contains a <a>codec string</a> describing the codec.</dd>

  <dt><dfn dict-member for=VideoEncoderConfig>bitrate</dfn></dt>
  <dd>The average bitrate of the encoded video given in units of bits per second.</dd>

  <dt><dfn dict-member for=VideoEncoderConfig>cropWidth</dfn></dt>
  <dd>
    The encoded width of output {{EncodedVideoChunk}}s in pixels, prior to any
    display aspect ratio adjustments.

    The encoder must scale any {{VideoFrame}} who's {{VideoFrame/cropWidth}}
    differs from this value.
  </dd>

  <dt><dfn dict-member for=VideoEncoderConfig>cropHeight</dfn></dt>
  <dd>
    The encoded height of output {{EncodedVideoChunk}}s in pixels, prior to any
    display aspect ratio adjustments.

    The encoder must scale any {{VideoFrame}} who's {{VideoFrame/cropHeight}}
    differs from this value.
  </dd>
</dl>

<div class='note'>
  NOTE: The {{VideoEncoder}} will scale, not crop, input {{VideoFrame}}s to the
      specified {{VideoEncoderConfig/cropWidth}} and
      {{VideoEncoderConfig/cropHeight}}.

      The naming of {{VideoEncoderConfig/cropWidth}} and
      {{VideoEncoderConfig/cropHeight}} reflects that the encoded chunks may be
      decoded to produce {{VideoFrame}}s who's {{VideoFrame/cropWidth}}
      and {{VideoFrame/cropHeight}} will match these values.
</div>

<dl>
  <dt><dfn dict-member for=VideoEncoderConfig>displayWidth</dfn></dt>
  <dd>
    The intended display width of output {{EncodedVideoChunk}}s in pixels.
    Defaults to {{VideoEncoderConfig/cropWidth}} if not present.
  </dd>

  <dt><dfn dict-member for=VideoEncoderConfig>displayHeight</dfn></dt>
  <dd>
    The intended display height of output {{EncodedVideoChunk}}s in pixels.
    Defaults to {{VideoEncoderConfig/cropWidth}} if not present.
  </dd>
</dl>

<div class='note'>
  NOTE: Providing a {{VideoEncoderConfig/displayWidth}} or
      {{VideoEncoderConfig/displayHeight}} that differs from the crop dimensions
      signals that chunks should be scaled after decoding to arrive at the final
      display aspect ratio.

      For many codecs this is merely pass-through information, but some codecs
      may optionally include display sizing in the bitstream.
</div>

<dl>
  <dt><dfn dict-member for=VideoEncoderConfig>avc</dfn></dt>
  <dd>Contains codec specific configuration options for the AVC (H.264) codec.</dd>

  <dt><dfn dict-member for=VideoEncoderConfig>acceleration</dfn></dt>
  <dd>
    Configures hardware accleration for this codec. See
    {{HardwareAcceleration}}.
  </dd>
</dl>

### AvcEncoderConfig ### {#avc-encoder-config}
<pre class='idl'>
<xmp>
dictionary AvcEncoderConfig {
  AvcBitstreamFormat format = "avc";
};
</xmp>
</pre>

<dl>
  <dt><dfn dict-member for=AvcEncoderConfig>format</dfn></dt>
  <dd>
    Configures the format of output <a>AVC</a> {{EncodedVideoChunk}}s. See
    {{AvcBitstreamFormat}}.
  </dd>
</dl>

#### AvcBitstreamFormat #### {#avc-bitstream-format}
<pre class='idl'>
<xmp>
enum AvcBitstreamFormat {
  "annexb",
  "avc",
};
</xmp>
</pre>
The {{AvcBitstreamFormat}} determines the location of <a>Sequence Parameter
Set (SPS)</a> and <a>Picture Parameter Set (PPS)</a> data, and mechanisms for
packaging the bitstream.

<dl>
  <dt><dfn enum-value for=AvcBitstreamFormat>annexb</dfn></dt>
  <dd>
    This format is as described by [[!iso14496-10]], Annex B. Notably,
    <a>SPS</a> and <a>PPS</a> data are included periodically throughout the
    bitstream.

    NOTE: This format is commonly used in live-streaming applications, where
        including the SPS and PPS data periodically allows users to easily start
        from the middle of the stream.
  </dd>
  <dt><dfn enum-value for=AvcBitstreamFormat>avc</dfn></dt>
  <dd>
    This format is as described by [[!iso14496-15]], Section 5. Notably,
    <a>SPS</a> and <a>PPS</a> data are not included in the bitstream and are
    instead passed out of band as a AVCDecoderConfigurationRecord as defined by
    [[!iso14496-15]]. This structure is emitted via the
    {{VideoEncoder/[[output callback]]}} as the
    {{VideoDecoderConfig/description}} of the {{VideoDecoderConfig}}
    |output_config|.

    NOTE: This format is commonly used in .MP4 files, where the player generally
        has random access to the media data.
</dl>

Hardware Acceleration{#hardware-acceleration}
---------------------------------------------
<pre class='idl'>
<xmp>
enum HardwareAcceleration {
  "allow",
  "deny",
  "require",
};
</xmp>
</pre>

When supported, hardware acceleration offloads encoding or decoding to
specialized hardware, reducing codec CPU usage and power consumption.

<dl>
  <dt><dfn enum-value for=HardwareAcceleration>allow</dfn></dt>
  <dd>
    Indicates that the user agent may use hardware acceleration if it is
    available and compatible with other aspects of the codec configuration.
  </dd>
  <dt><dfn enum-value for=HardwareAcceleration>deny</dfn></dt>
  <dd>
    Indicates that the user agent must not use hardware acceleration.

    NOTE: This will cause the configuration to be unsupported on platforms where
    an unaccelerated codec is unavailable or is incompatible with other aspects
    of the codec configuration.
  </dd>
  <dt><dfn enum-value for=HardwareAcceleration>require</dfn></dt>
  <dd>
    Indicates that the user agent must use hardware acceleration.

    NOTE: This will cause the configuration to be unsupported on platforms where
    an accelerated codec is unavailable or is incompatible with other aspects of
    the codec configuration.
  </dd>
</dl>

Configuration Equivalence{#config-equivalence}
----------------------------------------------
Two dictionaries are <dfn>equal dictionaries</dfn> if they contain the same
keys and values. For nested dictionaries, apply this definition recursively.


VideoEncoderEncodeOptions{#video-encoder-options}
-------------------------------------------------

<pre class='idl'>
<xmp>
dictionary VideoEncoderEncodeOptions {
  boolean keyFrame = false;
};
</xmp>
</pre>

<dl>
  <dt><dfn dict-member for=VideoEncoderEncodeOptions>keyFrame</dfn></dt>
  <dd>
    A value of `true` indicates that the given frame MUST be encoded as a key
    frame. A value of `false` indicates that the user agent has flexibility to
    decide whether the frame will be encoded as a key frame.
  </dd>
</dl>


CodecState{#codec-state}
------------------------
<pre class='idl'>
<xmp>
enum CodecState {
  "unconfigured",
  "configured",
  "closed"
};
</xmp>
</pre>

<dl>
  <dt><dfn enum-value for=CodecState>unconfigured</dfn></dt>
  <dd>The codec is not configured for encoding or decoding.</dd>
  <dt><dfn enum-value for=CodecState>configured</dfn></dt>
  <dd>
    A valid configuration has been provided. The codec is ready for encoding or
        decoding.
  </dd>
  <dt><dfn enum-value for=CodecState>closed</dfn></dt>
  <dd>
    The codec is no longer usable and underlying system resources have been
      released.
  </dd>
</dl>

WebCodecsErrorCallback{#error-callback}
---------------------------------------
<pre class='idl'>
<xmp>
callback WebCodecsErrorCallback = undefined(DOMException error);
</xmp>
</pre>


Encoded Media Interfaces (Chunks) {#encoded-media-interfaces}
=============================================================
These interfaces represent chunks of encoded media.

EncodedAudioChunk Interface {#encodedaudiochunk-interface}
------------------------------------------------------------
<pre class='idl'>
<xmp>
interface EncodedAudioChunk {
  constructor(EncodedAudioChunkInit init);
  readonly attribute EncodedAudioChunkType type;
  readonly attribute unsigned long long timestamp;  // microseconds
  readonly attribute ArrayBuffer data;
};

dictionary EncodedAudioChunkInit {
  required EncodedAudioChunkType type;
  required unsigned long long timestamp;
  required BufferSource data;
};

enum EncodedAudioChunkType {
    "key",
    "delta",
};
</xmp>
</pre>

### Constructors ###{#encodedaudiochunk-constructors}
<dfn constructor for=EncodedAudioChunk title="EncodedAudioChunk(init)">
  EncodedAudioChunk(init)
</dfn>
1. Let |chunk| be a new {{EncodedAudioChunk}} object, initialized as follows
    1. Assign `init.type` to `chunk.type`.
    2. Assign `init.timestamp` to `chunk.timestamp`.
    3. Assign a copy of `init.data` to `chunk.data`.
5. Return |chunk|.

### Attributes ###{#encodedaudiochunk-attributes}
<dl>
  <dt><dfn attribute for=EncodedAudioChunk>type</dfn></dt>
  <dd>Describes whether the chunk is a key frame.</dd>

  <dt><dfn attribute for=EncodedAudioChunk>timestamp</dfn></dt>
  <dd>The presentation timestamp, given in microseconds.</dd>

  <dt><dfn attribute for=EncodedAudioChunk>data</dfn></dt>
  <dd>A sequence of bytes containing encoded audio data.</dd>
</dl>

EncodedVideoChunk Interface{#encodedvideochunk-interface}
-----------------------------------------------------------
<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface EncodedVideoChunk {
  constructor(EncodedVideoChunkInit init);
  readonly attribute EncodedVideoChunkType type;
  readonly attribute unsigned long long timestamp;  // microseconds
  readonly attribute unsigned long long? duration;  // microseconds
  readonly attribute ArrayBuffer data;
};

dictionary EncodedVideoChunkInit {
  required EncodedVideoChunkType type;
  required unsigned long long timestamp;
  unsigned long long duration;
  required BufferSource data;
};

enum EncodedVideoChunkType {
    "key",
    "delta",
};
</xmp>
</pre>

### Constructors ###{#encodedvideochunk-constructors}
<dfn constructor for=EncodedVideoChunk title="EncodedVideoChunk(init)">
  EncodedVideoChunk(init)
</dfn>
1. Let |chunk| be a new {{EncodedVideoChunk}} object, initialized as follows
    1. Assign `init.type` to `chunk.type`.
    2. Assign `init.timestamp` to `chunk.timestamp`.
    3. If duration is present in init, assign `init.duration` to
        `chunk.duration`. Otherwise, assign null to `chunk.duration`.
2. Assign a copy of `init.data` to `chunk.data`.
3. Return |chunk|.

### Attributes ###{#encodedvideochunk-attributes}
<dl>
  <dt><dfn attribute for=EncodedVideoChunk>type</dfn></dt>
  <dd>Describes whether the chunk is a key frame or not.</dd>

  <dt><dfn attribute for=EncodedVideoChunk>timestamp</dfn></dt>
  <dd>The presentation timestamp, given in microseconds.</dd>

  <dt><dfn attribute for=EncodedVideoChunk>duration</dfn></dt>
  <dd>The presentation duration, given in microseconds.</dd>

  <dt><dfn attribute for=EncodedVideoChunk>data</dfn></dt>
  <dd>A sequence of bytes containing encoded video data.</dd>
</dl>


Raw Media Interfaces (Frames){#raw-media-interfaces}
====================================================
These interfaces represent unencoded (raw) media.


AudioFrame Interface {#audioframe-interface}
---------------------------------------------

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface AudioFrame {
  constructor(AudioFrameInit init);
  readonly attribute unsigned long long timestamp;
  readonly attribute AudioBuffer? buffer;
  undefined close();
};

dictionary AudioFrameInit {
  required unsigned long long timestamp;
  required AudioBuffer buffer;
};
</xmp>
</pre>

### Internal Slots ###{#audioframe-internal-slots}
<dl>
  <dt><dfn attribute for=AudioFrame>\[[detached]]</dfn></dt>
  <dd>
    Boolean indicating whether close() was invoked and underlying resources
        have been released.
  </dd>
</dl>


### Constructors ###{#audioframe-constructors}
<dfn constructor for=AudioFrame title="AudioFrame(init)">
  AudioFrame(init)
</dfn>
1. Let |frame| be a new {{AudioFrame}} object.
2. Assign `init.timestamp` to `frame.timestamp`.
3. Assign `init.buffer` to `frame.buffer`.
4. Assign `false` to the {{AudioFrame/[[detached]]}} internal slot.
5. Return |frame|.


### Attributes ###{#audioframe-attributes}
<dl>
  <dt><dfn attribute for=AudioFrame>timestamp</dfn></dt>
  <dd>The presentation timestamp, given in microseconds.</dd>

  <dt><dfn attribute for=AudioFrame>buffer</dfn></dt>
  <dd>The buffer containing decoded audio data.</dd>
</dl>


### Methods ###{#audioframe-methods}
<dl>
  <dt><dfn method for=AudioFrame>close()</dfn></dt>
  <dd>
    Immediately frees system resources. When invoked, run these steps:
    1. Release system resources for buffer and set its value to null.
    2. Assign `true` to the {{AudioFrame/[[detached]]}} internal slot.

    NOTE: This section needs work. We should use the name and semantics of
        VideoFrame destroy(). Similarly, we should add clone() to make a deep
        copy.
  </dd>
</dl>

VideoFrame Interface {#videoframe-interface}
--------------------------------------------

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface VideoFrame {
  constructor(ImageBitmap imageBitmap, VideoFrameInit frameInit);
  constructor(PixelFormat pixelFormat, sequence<(Plane or PlaneInit)> planes,
              VideoFrameInit frameInit);

  readonly attribute PixelFormat format;
  readonly attribute FrozenArray<Plane> planes;
  readonly attribute unsigned long codedWidth;
  readonly attribute unsigned long codedHeight;
  readonly attribute unsigned long cropLeft;
  readonly attribute unsigned long cropTop;
  readonly attribute unsigned long cropWidth;
  readonly attribute unsigned long cropHeight;
  readonly attribute unsigned long displayWidth;
  readonly attribute unsigned long displayHeight;
  readonly attribute unsigned long long? duration;
  readonly attribute unsigned long long? timestamp;

  undefined destroy();
  VideoFrame clone();

  Promise<ImageBitmap> createImageBitmap(
    optional ImageBitmapOptions options = {});

};

dictionary VideoFrameInit {
  unsigned long codedWidth;
  unsigned long codedHeight;
  unsigned long cropLeft;
  unsigned long cropTop;
  unsigned long cropWidth;
  unsigned long cropHeight;
  unsigned long displayWidth;
  unsigned long displayHeight;
  unsigned long long duration;
  unsigned long long timestamp;
};
</xmp>
</pre>

### Internal Slots ###{#videoframe-internal-slots}
<dl>
  <dt><dfn attribute for=VideoFrame>\[[detached]]</dfn></dt>
  <dd>
    Boolean indicating whether {{destroy()}} was invoked and underlying
        resources have been released.
  </dd>
</dl>

### Constructors ###{#videoframe-constructors}

NOTE: this section needs work. Current wording assumes a VideoFrame can always
    be easily represented using one of the known pixel formats. In practice, the
    underlying UA resources may be GPU backed or formatted in such a way that
    conversion to an allowed pixel format requires expensive copies and
    translation. When this occurs, we should allow planes to be null and format
    to be “opaque” to avoid early optimization. We should make conversion
    explicit and user controlled by offering a `videoFrame.convertTo(format)`
    that returns a Promise containing a new VideoFrame for which the
    copies/translations are performed.

<dfn constructor for=VideoFrame title="VideoFrame(imageBitmap, frameInit)">
  VideoFrame(imageBitmap, frameInit)
</dfn>
1. If |frameInit| is not a <a>valid VideoFrameInit</a>, throw a {{TypeError}}.
2. If the value of |imageBitmap|'s' {{PlatformObject/[[Detached]]}} internal
    slot is set to `true`, then throw an {{InvalidStateError}} DOMException.
3. Let |frame| be a new {{VideoFrame}}.
4. Assign `false` to |frame|’s {{VideoFrame/[[detached]]}} internal slot.
5. Use a copy of the pixel data in |imageBitmap| to initialize to following
    frame attributes:
    1. Initialize `frame.pixelFormat` be the underlying format of imageBitmap.
    2. Initialize `frame.planes` to describe the arrangement of memory of the
        copied pixel data.
    3. Assign regions of the copied pixel data to the
        {{Plane/[[plane buffer]]}} internal slot of each plane as
        appropriate for the pixel format.
    4. Initialize `frame.codedWidth` and `frame.codedHeight` describe the width
        and height of the imageBitamp prior to any cropping or aspect ratio
        adjustments.
6. Use |frameInit| to initialize the remaining frame attributes:
    1. If `frameInit.cropLeft` is present, initialize it `frame.cropLeft`.
        Otherwise, default `frame.cropLeft` to zero.
    2. If `frameInit.cropTop` is present, initialize it to `frame.cropTop`.
        Otherwise, default `frame.cropTop` to zero.
    3. If `frameInit.cropWidth` is present, initialize it to `frame.cropWidth`.
        Otherwise, default `frame.cropWidth` to `frame.codedWidth`.
    4. If `frameInit.cropHeight` is present, initialize it to
        `frame.cropHeight`. Otherwise, default `frame.cropHeight` to
        `frame.codedHeight`.
    5. If `frameInit.displayWidth` is present, initialize it to
        `frame.displayWidth`. Otherwise, default `frame.displayWidth` to
        `frame.codedWidth`.
    6. If `frameInit.displayHeight` is present, initialize it to
        `frame.displayHeight`. Otherwise, default `frame.displayHeight` to
        `frame.codedHeight`.
    7. If `frameInit.duration` is present, initialize it to `frame.duration`.
        Otherwise, default `frame.duration` to null.
    8. If `frameInit.timestamp` is present, initialize it to `frame.timestamp`.
        Otherwise default `frame.timestamp` to null.
7. Return |frame|.

<dfn constructor for=VideoFrame title="VideoFrame(pixelFormat, planes, frameInit)">
  VideoFrame(pixelFormat, planes, frameInit)
</dfn>
1. If either {{VideoFrameInit/codedWidth}} or {{VideoFrameInit/codedHeight}} is
    not present in |frameInit|, throw a {{TypeError}}.
2. If |frameInit| is not a <a>valid VideoFrameInit</a>, throw a {{TypeError}}.
3. If the length of |planes| is incompatible with the given pixelFormat, throw a
    TypeError.
4. Let |frame| be a new {{VideoFrame}} object.
5. Assign `false` to |frame|’s {{VideoFrame/[[detached]]}} internal slot.
6. Assign `init.pixelFormat` to `frame.pixelFormat`.
7. For each element |p| in |planes|:
    1. If |p| is a {{Plane}}, append a copy of p to `frame.planes`. Continue
        processing the next element.
    2. If |p| is a {{PlaneInit}}, append a new {{Plane}} <var ignore>q</var> to
        `frame.planes` initialized as follows:
        2. Assign a copy of `p.src` to q's [[plane buffer]] internal slot.

        NOTE: the samples should be copied exactly, but the user agent may add
            row padding as needed to improve memory alignment.

        3. Assign the width of each row in [[plane buffer]], including any
            padding, to  `q.stride`.
        4. Assign `p.rows` to `q.rows`.
        5. Assign the product of (`q.rows` * `q.stride)` to `q.length`
8. Assign `frameInit.codedWidth` to `frame.codedWidth`.
9. Assign `frameInit.codedHeight` to `frame.codedHeight`.
10. If `frameInit.cropLeft` is present, assign it `frame.cropLeft`. Otherwise,
    default `frame.cropLeft` to zero.
11. If `frameInit.cropTop` is present, assign it to `frame.cropTop`. Otherwise,
    default `frame.cropTop` to zero.
12. If `frameInit.cropWidth` is present, assign it to `frame.cropWidth`.
    Otherwise, default `frame.cropWidth` to `frame.codedWidth`.
13. If `frameInit.cropHeight` is present, assign it to `frame.cropHeight`.
    Otherwise, default `frame.cropHeight` to `frame.codedHeight`.
14. If `frameInit.displayWidth` is present, assign it to `frame.displayWidth`.
    Otherwise, default `frame.displayWidth` to `frame.codedWidth`.
15. If `frameInit.displayHeight` is present, assign it to `frame.displayHeight`.
    Otherwise, default `frame.displayHeight` to `frame.codedHeight`.
16. If `frameInit.duration` is present, assign it to `frame.duration`.
    Otherwise, default `frame.duration` to null.
17. If `frameInit.timestamp` is present, assign it to `frame.timestamp`.
    Otherwise, default `frame.timestamp` to null.
18. Return frame.

### Attributes ###{#videoframe-attributes}
<dl>
  <dt><dfn attribute for=VideoFrame>timestamp</dfn></dt>
  <dd>
    The presentation timestamp, given in microseconds. The timestamp is copied
        from the EncodedVideoChunk corresponding to this VideoFrame.
  </dd>
  <dt><dfn attribute for=VideoFrame>duration</dfn></dt>
  <dd>
    The presentation duration, given in microseconds. The duration is copied
        from the EncodedVideoChunk corresponding to this VideoFrame.
  </dd>
  <dt><dfn attribute for=VideoFrame>format</dfn></dt>
  <dd>
    Describes the arrangement of bytes in each plane as well as the number and
        order of the planes.
  </dd>
  <dt><dfn attribute for=VideoFrame>planes</dfn></dt>
  <dd>
    Holds pixel data data, laid out as described by format and Plane
        attributes.
  </dd>
  <dt><dfn attribute for=VideoFrame>codedWidth</dfn></dt>
  <dd>
    Width of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>
  <dt><dfn attribute for=VideoFrame>codedHeight</dfn></dt>
  <dd>
    Height of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>
  <dt><dfn attribute for=VideoFrame>cropLeft</dfn></dt>
  <dd>
    The number of pixels to remove from the left of the VideoFrame, prior to
        aspect ratio adjustments.
  </dd>
  <dt><dfn attribute for=VideoFrame>cropTop</dfn></dt>
  <dd>
    The number of pixels to remove from the top of the VideoFrame, prior to
        aspect ratio adjustments.
  </dd>
  <dt><dfn attribute for=VideoFrame>cropWidth</dfn></dt>
  <dd>The width of pixels to include in the crop, starting from cropLeft.</dd>
  <dt><dfn attribute for=VideoFrame>cropHeight</dfn></dt>
  <dd>The height of pixels to include in the crop, starting from cropLeft.</dd>
  <dt><dfn attribute for=VideoFrame>displayWidth</dfn>
  <dd>Width of the VideoFrame when displayed.</dd>
  <dt><dfn attribute for=VideoFrame>displayHeight</dfn></dt>
  <dd>Height of the VideoFrame when displayed.</dd>
</dl>

### Methods ###{#videoframe-methods}
<dfn method for=VideoFrame>destroy()</dfn>
Immediately frees system resources. Destruction applies to all references,
    including references that are serialized and passed across Realms.

NOTE: Authors should take care to manage frame lifetimes by calling
    {{VideoFrame/destroy()}} immediately when frames are no longer needed.

NOTE: Use clone() to create a deep copy. Cloned frames have their own lifetime
    and will not be affected by destroying the original frame.

When invoked, run these steps:
1. If {{VideoFrame/[[detached]]}} is `true`, throw an {{InvalidStateError}}.
2. Remove all {{Plane}}s from {{VideoFrame/planes}} and release associated
    memory.
3. Assign `true` to the {{VideoFrame/[[detached]]}} internal slot.

<dfn method for=VideoFrame>clone()</dfn>
Creates a new {{VideoFrame}} with a separate lifetime containing a deep copy of
    this frame’s resources.

NOTE:  VideoFrames may require a large amount of memory. Use
    {{VideoFrame/clone()}} sparingly.

When invoked, run the following steps:
1. If the value of the {{VideoFrame/[[detached]]}} slot is `true`, return
    [=a promise rejected with=] {{InvalidStateError}} {{DOMException}}.
2. Let |p| be a new Promise.
3. In parallel, resolve |p| with the result of running the <a>Clone Frame</a>
    algorithm with <a>this</a>.
4. Return |p|.

<dfn method for=VideoFrame>createImageBitmap(options)</dfn>
Creates an ImageBitmap from this {{VideoFrame}}.

When invoked, run these steps:
1. Let |p| be a new Promise.
2. If either |options|'s {{ImageBitmapOptions/resizeWidth}} or
    {{ImageBitmap/resizeHeight}} is present and is 0, then return |p| rejected
    with an {{InvalidStateError}} {{DOMException}}.
3. If the <a>this'</a> {{VideoFrame/[[detached]]}} internal slot is set to
    `true`, then return |p| rejected with an {{InvalidStateError}}
    {{DOMException}}.
4. Let |imageBitmap| be a new {{ImageBitmap}} object.
5. Set |imageBitmap|'s bitmap data to a copy of the {{VideoFrame}} pixel data,
    at the frame's intrinsic width and intrinsic height (`i.e`., after any
    aspect-ratio correction has been applied), cropped to the source rectangle
    with formatting.
6. If the origin of |imageBitmap|'s image is not same origin with entry settings
    object's origin, then set the origin-clean flag of |imageBitmap|'s bitmap to
    `false`.
7. Run this step in parallel:
  1. Resolve p with imageBitmap.

### Algorithms ###{#videoframe-algorithms}
To check if a {{VideoFrameInit}} is a <dfn>valid VideoFrameInit</dfn>,
run these steps:
1. If {{VideoFrameInit/codedWidth}} = 0 or {{VideoFrameInit/codedHeight}} = 0,
    return `false`.
2. If {{VideoFrameInit/cropWidth}} = 0 or {{VideoFrameInit/cropHeight}} = 0,
    return `false`.
3. If {{VideoFrameInit/cropTop}} + {{VideoFrameInit/cropHeight}} >=
    {{VideoFrameInit/codedHeight}}, return `false`.
4. If {{VideoFrameInit/cropLeft}} + {{VideoFrameInit/cropWidth}} >=
    {{VideoFrameInit/codedWidth}}, return `false`.
5. If {{VideoFrameInit/displayWidth}} = 0 or
    {{VideoFrameInit/displayHeight}} = 0, return `false`.
6. Return `true`.


Plane Interface {#plane-interface}
----------------------------------
A {{Plane}} acts like a thin wrapper around an {{ArrayBuffer}}, but may actually
    be backed by a texture. {{Plane}}s hide any padding before the first sample
    or after the last row.

A {{Plane}} is solely constructed by its {{VideoFrame}}. During construction,
    the User Agent may use knowledge of the frame’s {{PixelFormat}} to add
    padding to the {{Plane}} to improve memory alignment.

A {{Plane}} cannot be used after the {{VideoFrame}} is destroyed. A new
    {{VideoFrame}} can be assembled from existing {{Plane}}s, and the new
    {{VideoFrame}} will remain valid when the original is destroyed. This makes
    it possible to efficiently add an alpha plane to an existing {{VideoFrame}}.


<pre class='idl'>
<xmp>
interface Plane {
  readonly attribute unsigned long stride;
  readonly attribute unsigned long rows;
  readonly attribute unsigned long length;

  undefined readInto(ArrayBufferView dst);
};

dictionary PlaneInit {
  required BufferSource src;
  required unsigned long stride;
  required unsigned long rows;
};
</xmp>
</pre>

### Internal Slots ###{#plane-internal-slots}
<dl>
  <dt><dfn attribute for=Plane>[[parent frame]]</dfn></dt>
  <dd>Refers to the {{VideoFrame}} that constructed and owns this plane.</dd>
  <dt><dfn attribute for=Plane>[[plane buffer]]</dfn></dt>
  <dd>Internal storage for the plane’s pixel data.</dd>
</dl>

### Attributes ###{#plane-attributes}
<dl>
  <dt><dfn attribute for=Plane>stride</dfn></dt>
  <dd>The width of each row including any padding.</dd>
  <dt><dfn attribute for=Plane>rows</dfn></dt>
  <dd>The number of rows.</dd>
  <dt><dfn attribute for=Plane>length</dfn></dt>
  <dd>The total byte length of the plane (stride * rows).</dd>
</dl>

### Methods ###{#plane-methods}
<dfn method for=Plane>readInto(dst)</dfn>

Copies the plane data into dst.

When invoked, run these steps:
1. If {{Plane/[[parent frame]]}} has been destroyed, throw an
    {{InvalidStateError}}.
2. If {{Plane/length}} is greater than |`dst.byteLength`|, throw a
    {{TypeError}}.
3. Copy the {{Plane/[[plane buffer]]}} into <var ignore>dst</var>.


Pixel Format{#pixel-format}
---------------------------
Pixel formats describe the arrangement of bytes in each plane as well as the
number and order of the planes.

NOTE: This section needs work. We expect to add more pixel formats and offer
    much more verbose definitions. For now, please see
    <a href="http://www.fourcc.org/pixel-format/yuv-i420/">
    http://www.fourcc.org/pixel-format/yuv-i420/</a> for a more complete
    description.

<pre class='idl'>
<xmp>
enum PixelFormat {
  "I420"
};
</xmp>
</pre>

<dl>
  <dt><dfn enum-value for=PixelFormat>I420</dfn></dt>
  <dd>
    Planar 4:2:0 YUV.
  </dd>
</dl>


Algorithms{#raw-media-algorithms}
---------------------------------
<h3 id='clone-frame-algo'><dfn>Clone Frame</dfn> (with |frame|)</h3>

1. Let |cloneFrame| be a new object of the same type as frame (either
    {{AudioFrame}} or {{VideoFrame}}).
2. Initialize each attribute and internal slot of clone with a copy of the value
    from the corresponding attribute of this frame.

NOTE: User Agents are encouraged to avoid expensive copies of large objects
    (for instance, {{VideoFrame}} pixel data). Frame types are immutable, so the
    above step may be implemented using memory sharing techniques such as
    reference counting.

3. Return |cloneFrame|.


VideoTrackReader Interface{#videotrackreader-interface}
=======================================================
{{VideoTrackReader}} emits {{VideoFrame}}s from a {{MediaStreamTrack}}. Authors
may use this interface to manipulate, render, or encode streams from
{{mediaDevices/getUserMedia()}} and {{mediaDevices/getDisplayMedia()}}.

<pre class='idl'>
<xmp>
[Exposed=Window]
interface VideoTrackReader {
  constructor(MediaStreamTrack track);

  readonly attribute VideoTrackReaderState readyState;
  attribute EventHandler onended;

  undefined start(VideoFrameOutputCallback callback);
  undefined stop();
};

enum VideoTrackReaderState {
  "started",
  "stopped",
  "ended"
};
</xmp>
</pre>

VideoTrackReaderState Values{#videotrackreaderreadystate}
--------------------------------------------------------------
<dl>
  <dt><dfn enum-value for=VideoTrackReaderState>started</dfn></dt>
  <dd>
    Indicates that the {{VideoTrackReader/[[track]]}} is
        {{MediaStreamTrackState/live}} and {{VideoFrame}}s are being output to
        the {{VideoTrackReader/[[callback]]}} provided to
        {{VideoTrackReader/start()}}.

  </dd>
  <dt><dfn enum-value for=VideoTrackReaderState>stopped</dfn></dt>
  <dd>
    Indicates that the {{VideoTrackReader/[[track]]}} is
        {{MediaStreamTrackState/live}}, but the
        {{VideoTrackReader/[[callback]]}} is not set, so no {{VideoFrame}}s are
        being output.
  </dd>
  <dt><dfn enum-value for=VideoTrackReaderState>ended</dfn></dt>
  <dd>
    Indicates that the {{VideoTrackReader/[[track]]}} is
        {{MediaStreamTrackState/ended}} and this object can no longer be
        {{VideoTrackReaderState/started}} nor {{VideoTrackReaderState/stopped}}.
  </dd>
</dl>

Internal Slots {#videotrackreader-slots}
----------------------------------------
<dl>
  <dt><dfn attribute for=VideoTrackReader>\[[track]]</dfn></dt>
  <dd>The {{MediaStreamTrack}} provided at construction.</dd>
  <dt><dfn attribute for=VideoTrackReader>\[[callback]]</dfn></dt>
  <dd>
    The {{VideoFrameOutputCallback}} assigned by the last call to
      {{VideoTrackReader/start()}}.
  </dd>
</dl>


Constructors{#videotrackreader-constructors}
---------------------------------------------
<dfn constructor for=VideoTrackReader title="VideoTrackReader(track)">
  VideoTrackReader(track)
</dfn>
1. If `track.kind` is not `"video"`, throw a {{TypeError}}.
2. If `track.readyState` is `"ended"`, throw an {{InvalidStateError}}.
3. Let |reader| be a new {{VideoTrackReader}} object.
4. Assign <var ignore>track</var> to the {{VideoTrackReader/[[track]]}} internal
    slot.
5. Assign `"stopped"` to `reader.readyState`.
6. Return |reader|.


Attributes{#videotrackreader-attributes}
----------------------------------------
<dl>
  <dt><dfn attribute for=VideoTrackReader>readyState</dfn></dt>
  <dd>
    Indicates the current state of the {{VideoTrackReader}} object.
  </dd>
  <dt><dfn attribute for=VideoTrackReader>onended</dfn></dt>
  <dd>The event handler for the ended event.</dd>
</dl>

Event Summary{#videotrackreader-events}
---------------------------------------
<dl>
  <dt><dfn event for=VideoTrackReader>ended</dfn></dt>
  <dd>
    Dispatched when the {{VideoTrackReader/[[track]]}}'s
        {{VideoTrackReader/readyState}} becomes `"ended"`, indicating no further
        {{VideoFrame}}s will be output.
  </dd>
</dl>


Methods{#videotrackreader-methods}
----------------------------------
<dfn method for=VideoTrackReader>start(callback)</dfn>

Starts calling the callback with {{VideoFrame}}s from the {{MediaStreamTrack}}.

When invoked, run these steps:
1. If {{VideoTrackReader/readyState}} is not `"stopped"`, throw an
    {{InvalidStateError}}.
2. Assign `"started"` to {{VideoTrackReader/readyState}}.
3. Assign <var ignore>callback</var> to the {{VideoTrackReader/[[callback]]}}
    internal slot.
4. In parallel, <a>run the track monitor</a>.

<dfn method for=VideoTrackReader>stop()</dfn>

Stops calling the {{VideoFrameOutputCallback}} with {{VideoFrame}}s from the
    {{MediaStreamTrack}}.

When invoked, run these steps:
1. If readyState is not `"started"`, throw an {{InvalidStateError}}.
2. Cease <a>running the track monitor</a>.
3. Assign `"stopped"` to the {{VideoTrackReader/readyState}}.
4. Assign `null` to the {{VideoTrackReader/[[callback]]}} internal slot.


MediaStreamTrack Monitoring{#mediastreamtrack-monitoring}
---------------------------------------------------------

The <dfn export>track monitor</dfn> may be started and stopped by the user to
    control the calling of the {{VideoFrameOutputCallback}}.

<dfn lt="running the track monitor|run the track monitor">Running the track
    monitor</dfn> means monitoring {{VideoTrackReader/[[track]]}} for the
    arrival of new picture data as well as changes to `[[track]].readyState`.

While `[[track]].readyState` is {{MediaStreamTrackState/live}}, for each new
    picture that arrives in {{VideoTrackReader/[[track]]}}, perform the
    following steps:

    NOTE: Pictures that arrived prior to the start of this loop are not
        considered.


    NOTE: Video data in a MediaStreamTrack does not have a canonical binary
        form. The user agent should tokenize "pictures" by discrete times of
        capture. For example, if the source is a camera capturing 60 frames per
        second, the UA should construct 60 corresponding VideoFrame's each
        second.

1. Let |planes| be a sequence of {{Plane}}s containing the picture data.
2. Let |pixelFormat| be the {{PixelFormat}} of |planes|.

    NOTE: This section needs work. The UA should avoid early optimizations to
        convert between PixelFormats, but currently only a narrow set of formats
        is defined in this spec. We should consider adding an "opaque" format
        along with an API coverter API to make pixel format conversion
        transparent to authors.


3. Let |frameInit| be an {{VideoFrameInit}} with the following keys:
    1. Let <var ignore>timestamp</var> and <var ignore>duration</var> be the
        presentation timestamp and (optionally) presentation duration as
        determined by the {{VideoTrackReader/[[track]]}} source.
    2. Let <var ignore>codedWidth</var> and <var ignore>codedHeight> be the
        width and height of the decoded video frame in pixels, prior to any
        cropping or aspect ratio adjustments.
    3. Let <var ignore>cropLeft</var>, <var ignore>cropTop</var>,
        <var ignore>cropWidth</var>, and <var ignore>cropHeight</var> be the
        crop region of the decoded video frame in pixels, prior to any aspect
        ratio adjustments.
    4. Let <var ignore>displayWidth</var> and <var ignore>displayHeight</var>
        be the display size of the decoded video frame in pixels.
4. Let |frame| be a {{VideoFrame}}, constructed with |pixelFormat|,
        |planes|, and |frameInit|.
5. Invoke {{VideoTrackReader/[[callback]]}} with |frame|.

If {{VideoTrackReader/[[track]]}}.readyState becomes `"ended"`,
    <a>queue a task</a> on the media element task source to run the
    following steps:

1. Set {{VideoTrackReader/readyState}} to "ended".
2. <a>Queue a task</a> on the media element task source to run a simple
    event named {{VideoTrackReader/ended}} at the {{VideoTrackReader}}.
